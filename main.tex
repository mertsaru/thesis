\documentclass[12pt,twoside]{report}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
%\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

\usepackage{times}


\usepackage{url}
\makeatletter
\def\url@allbreakstyle{%
  \def\UrlBreaks{\do\.\do\@\do\\\do\/\do\!\do\_\do\|\do\;\do\>\do\]%
    \do\)\do\,\do\?\do\'\do+\do\=\do\#%
    \do A\do B\do C\do D\do E\do F\do G\do H\do I\do J\do K\do L\do M%
    \do N\do O\do P\do Q\do R\do S\do T\do U\do V\do W\do X\do Y\do Z%
    \do a\do b\do c\do d\do e\do f\do g\do h\do i\do j\do k\do l\do m%
    \do n\do o\do p\do q\do r\do s\do t\do u\do v\do w\do x\do y\do z%
    \do 0\do 1\do 2\do 3\do 4\do 5\do 6\do 7\do 8\do 9%
  }%
}
\def\url@restrictedbreakstyle{%
  \def\UrlBreaks{\do\.\do\@\do\\\do\/\do\!\do\_\do\|\do\;\do\>\do\]%
    \do\)\do\,\do\?\do\'\do+\do\=\do\#}%
}
\makeatother
\urlstyle{allbreak}%

% Useful packages
\usepackage{amsmath,bm,bbold}
\usepackage{graphicx}
\usepackage[export]{adjustbox}

\graphicspath{ {images/} }
\usepackage{subcaption}
\usepackage{lipsum}
\usepackage[colorlinks=true, allcolors=black]{hyperref}
\usepackage{setspace}
\usepackage{float}
\usepackage{fancyhdr}
\usepackage{indentfirst}
\usepackage{tcolorbox}

\setlength{\headheight}{15pt}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}

\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\usepackage{titlesec}

%\setcounter{secnumdepth}{4}
\usepackage[a4paper,width=150mm,top=25mm,bottom=25mm,bindingoffset=10mm]{geometry}
%\titleformat{\paragraph}
%{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
%\titlespacing*{\paragraph}
%{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\title{Cognitive Bias-Powered GLVQ: Illogical Machines}
\author{Mert Saruhan\\[.2cm]{\small Supervisor: Prof. Dr. rer. nat. habil. Thomas Villmann}\\[.2cm]{\small 2. Supervisor: Prof. Dr. rer. nat. habil. Thomas Villmann}}

\begin{document}

\begin{titlepage}
  \begin{center}
    \vspace*{1cm}
    Faculty of \textbf{Applied Computer Sciences and Biosciences}\\
    \rule{10cm}{.01cm}\\
    \vspace{\fill}
    \Huge
    \textbf{MASTER THESIS}

    \rule{10cm}{.01cm}\\
      \Huge
      \textbf{Cognitive Bias-Powered GLVQ: Illogical Machines}

      \Large
      \vspace{.5cm}

      Author: \textbf{Mert Saruhan}


      \vspace{0.5cm}
      \large
      \text{$1^{\text{st}}$ Examiner: Prof. Dr. rer. nat. habil. Thomas Villmann}

      \text{$2^{\text{nd}}$ Examiner: Dr. rer. nat. Marika Kaden}
      \vfill

      \large A thesis submitted in partial fulfillment \\
      of the requirements for the degree of \\
      Master of Applied Mathematics for Network and Data Sciences

      \vspace{0.8cm}
      \vspace{0.8cm}

      \includegraphics[width=0.4\textwidth]{hsmw}

      \Large
      Mittweida University of Applied Sciences\\
      Applied Mathematics for Network and Data Sciences\\
      Mittweida, Germany\\
      \vspace{0.5cm}
      Submission: 08 October 2023

    \end{center}
  \end{titlepage}

  \pagenumbering{roman}
  \chapter*{\centering Declaration}
  \begin{spacing}{1.5}
    This thesis is submitted in partial fulfillment of the requirements for the degree of Master of Science in Applied Mathematics for Network and Data Sciences at the Mittweida University of Applied Sciences (Hochschule Mittweida).

  I declare that this work has been completed according to the guidelines established by the faculty and has not been submitted for any other purpose.

  This thesis is copyrighted by its author, Mert Saruhan. It may be used or reproduced for educational purposes only, given proper credit to its author.
  \vspace{15pt}

  \noindent Mittweida, Germany

  \noindent 08 October 2023
  \vspace{10pt}

  \noindent Mert Saruhan
\end{spacing}

\chapter*{\centering Abstract}

\begin{spacing}{1.5}

\noindent In this paper, we conduct experiments to optimize the learning rates for the Generalized Learning Vector Quantization (GLVQ) model. Our approach leverages insights from cognitive science rooted in the profound intricacies of human thinking. Recognizing that human-like thinking has propelled humankind to its current state, we explore the applicability of cognitive science principles in enhancing machine learning.

\noindent Prior research has demonstrated promising results when applying learning rate methods inspired by cognitive science to Learning Vector Quantization (LVQ) models. In this study, we extend this approach to GLVQ models. Specifically, we examine five distinct cognitive science-inspired GLVQ variants: Conditional Probability (CP), Dual Factor Heuristic (DFH), Middle Symmetry (MS), Loose Symmetry (LS), and Loose Symmetry with Rarity (LSR).

\noindent Our experiments involve a comprehensive analysis of the performance of these cognitive science-derived learning rate techniques across various datasets, aiming to identify optimal settings and variants of cognitive science GLVQ model training. Through this research, we seek to unlock new avenues for enhancing the learning process in machine learning models by drawing inspiration from the rich complexities of human cognition.
\vspace{10pt}

\noindent \textit{Keywords}: machine learning, GLVQ, cognitive science, cognitive bias, learning rate optimization, optimizers, human-like learning, Conditional Probability (CP), Dual Factor Heuristic (DFH), Middle Symmetry (MS), Loose Symmetry (LS), Loose Symmetry with Rarity (LSR).

\end{spacing}
\chapter*{Acknowledgments}
\input{acknow}

\clearpage\begin{spacing}{1.5}
\tableofcontents
\listoffigures
\listoftables



\chapter*{Abbreviations}

\textbf{LVQ}: Learning Vector Quantization. 1

\textbf{GLVQ}: Generalized LVQ. 1

\textbf{OLVQ}: Optimized-Learning-Rate LVQ. 2

\textbf{OGLVQ}: Optimized-Learning-Rate GLVQ. 2

\textbf{CGLVQ}: Cognitive GLVQ. 2

\textbf{CP}: Conditional Probability. 1

\textbf{DFH}: Dual Factor Heuristic. 1

\textbf{MS}: Middle Symmetry. 1

\textbf{LS}: Loose Symmetry. 1

\textbf{LSR}: Loose Symmetry with Rarity. 1

\chapter*{Symbols}
\begin{itemize}

  \item $\mathbb{R}$: The set of real numbers. 3

  \item $\mathbb{C}$: The set of complex numbers. 3

  \item $i$: Imaginary unit ($=\sqrt{-1}$). 3

  \item $\mathbb{N}$: The set of natural numbers. 4

  \item $\Delta(t)$: Small time step in a discrete case. 4

  \item $x_{i}$: i$^{th}$ element (feature) of sample $\mathbb{x}$. 5

  \item $\mathbb{x}$: Feature array of a sample. 5

  \item $\ast$: Cross-correlation operator. 6

  \item $\otimes$: Convolution operator. 6

  \item \#: Means "number of". 15

  \item $\mathbb{x}^{c}$: Feature array of complex valued sample. 20

  \item $\omega$: Feature array of a prototype. 20

  \item $\mathbb{x}_i$: Feature array of the i$^{th}$ sample. 21

\item $y_{i}$: i$^{th}$ element (feature) of sample $\omega$. 20

\item $d(\mathbb{x},\omega_{j})$: Distance metric between feature arrays of $\mathbb{x}$ and $\omega_{j}$. 20

\item $\epsilon(t)$: Learning rate at time $t$. 20

\item $\epsilon(0)$: Initial ($t=0$) learning rate. 20

\item $\epsilon_{i}$: Local learning rate of i$^{th}$ prototype. 20

\item $\omega^{+}$: Feature array of the winner (closest) prototype with the same label as the sample. 21

\item $\omega^{-}$: Feature array of the winner (closest) prototype with a different label as the sample. 21

\item $d^{+}(\mathbb{x})$: Distance metric between $\mathbb{x}$ and $\omega^{+}$. 21

\item $d^{-}(\mathbb{x})$: Distance metric between $\mathbb{x}$ and $\omega^{-}$. 21

\item $\epsilon^{+}$: Local learning rate of winner prototype $\omega^{+}$. 21

\item $\epsilon^{-}$: Local learning rate of winner prototype $\omega^{-}$. 21

\item $\partial$: Partial derivative. 21

\item $\sigma$: Sigmoid function. 21

\item $\omega_{i}$: Feature array of i$^{th}$ prototype. 22

\item $L(\mathbb{x})$: label of sample $\mathbb{x}$. 24

\item $\omega^{\mathbb{x}}$: Feature array of the winner prototype of sample $\mathbb{x}$. 24

\item $R^{\text{XX}(q|p)}$: Causal relationship between $p$ and $q$ under given cognitive science model XX. 26

\item $R_{i}$: Causal relationship of $\omega_{i}$ under chosen cognitive science model. 28

\end{itemize}

\end{spacing}


\clearpage

\pagenumbering{arabic}
\pagestyle{fancy}

\chapter{Introduction}
\input{chapters/intro}

\chapter{Methods}
\input{chapters/method}

\chapter{Results}
\input{chapters/results}

\chapter{Discussion}
\input{chapters/conc}


\appendix
\setcounter{figure}{0}
\input{chapters/appendix}
\input{chapters/appendixb}


\begin{thebibliography}{26}

\bibitem{kohonen1}
Kohonen, T. (1995). Self-Organizing Maps (pp. 175-189). Springer-Verlag Berlin Heidelberg. \url{https://doi.org/10.1007/978-3-642-97610-0}.

\bibitem{kohonen2}
Kohonen, T. (1990). Improved versions of learning vector quantization. International Joint Conference on Neural Network. \url{https://doi.org/10.1109/ijcnn.1990.137622}.

\bibitem{cogn}
Takahashi, T., Nakano, M., \& Shinohara, S. (2010). Cognitive Symmetry: Illogical but Rational Biases. Symmetry Culture and Science. 21. 1-3. \url{https://www.researchgate.net/publication/285850238_Cognitive_Symmetry_Illogical_but_Rational_Biases}.

‌\bibitem{shinohara}
Shinohara, S., Taguchi, R., Katsurada, K., \& Nitta, T. (2007). A Model of Belief Formation Based on Causality and Application to N-armed Bandit Problem. Transactions of the Japanese Society for Artificial Intelligence, 22(1), 58–68. (in Japanese) \url{https://doi.org/10.1527/tjsai.22.58}.

‌
\bibitem{wasser}
Wasserman, E. A., Dorner, W. W., \& Kao, S. F. (1990). Contributions of specific cell information to judgments of interevent contingency. Journal of Experimental Psychology: Learning, Memory, and Cognition, 16(3), 509–521. \url{https://doi.org/10.1037/0278-7393.16.3.509}.

‌

\bibitem{els}
Taniguchi, H., Sato, H., \& Shirakawa, T. (2018). A machine learning model with human cognitive biases capable of learning from small and biased datasets. Scientific Reports, 8(1). \url{https://doi.org/10.1038/s41598-018-25679-z}.

‌
\bibitem{lrimp}
Manome, N., Shinohara, S., Takahashi, T., Chen, Y., \& Chung, U. (2021). Self-incremental learning vector quantization with human cognitive biases. Scientific Reports, 11(1). \url{https://doi.org/10.1038/s41598-021-83182-4}.


\bibitem{glass}
Evett, I. W., \& Spiehler, E. J. (1989). Rule induction in forensic science. Knowl. Based Syst. 152–160.

\bibitem{ion}
Sigillito, V. G., Wing, S. P., Hutton, L. V., \& Baker, K. B. (1989). Classification of radar returns from the ionosphere using neural networks.
Johns Hopkins APL Technical Digest 10, 262–266.

\bibitem{iris}
Fisher, R. A. (1936). The use of multiple measurements in taxonomic problems. Ann. Eugenics 7, 179–188.

\bibitem{sonar}
Gorman, R. P., \& Sejnowski, T. J. (1988). Analysis of hidden units in a layered network trained to classify sonar targets. Neural Netw. 1,
75–89.

\bibitem{cancer}
Bennett, K. P., \& Mangasarian, O. L. (1992). Robust linear programming discrimination of two linearly inseparable sets. Optimization Methods and Software, 1(1), 23–34. \url{https://doi.org/10.1080/10556789208805504}.


\bibitem{mypap}
Saruhan, M. (2023). Informational Image Data Preprocessing: IFE Blood Samples [Unpublished manuscript]. Applied Mathematics for Network and Data Sciences, Mittweida University of Applied Sciences.

\bibitem{four}
Zieliński, T. P. (2021). Discrete Fourier Transforms: DtFT and DFT. Springer EBooks, 65–92. \url{https://doi.org/10.1007/978-3-030-49256-4_4}.


\bibitem{googledev}
Google. (2022, July 18). Normalization. Google Developers. \url{https://developers.google.com/machine-learning/data-prep/transform/normalization}.

\bibitem{labpediaa}
Monoclonal Immunoglobulin (Ig), Monoclonal antibody, Immunofixation Electrophoresis (IFE) - Labpedia.net. (2020, January 25). \url{https://labpedia.net/monoclonal-immunoglobulin-ig-monoclonal-antibody-immunofixation-electrophoresis-ife/}
‌
\bibitem{testing}
Testing.com. (2021, March 24). Protein Electrophoresis, Immunofixation Electrophoresis. Testing.com. \url{https://www.testing.com/tests/protein-electrophoresis-immunofixation-electrophoresis/}.
‌

\bibitem{leung}
Leung, N.R. (2016). Chapter 8 : Clinical Tests for Monoclonal Proteins.

\bibitem{eclinpath}
Protein electrophoresis. (n.d.). EClinpath. \url{https://eclinpath.com/chemistry/proteins/electrophoretic-patterns/}.

‌
\bibitem{sato}
Sato, A., \& Yamada, K. (1995). Generalized Learning Vector Quantization. Neural Information Processing Systems, 8, 423–429.

‌

\bibitem{tversky}
Tversky, A., \& Kahneman, D. (1974). Judgment under uncertainty: Heuristics and Biases. Science, 185(4157), 1124–1131. \url{https://doi.org/10.1126/science.185.4157.1124}.

‌
\bibitem{hattori07}
Hattori, M., \& Oaksford, M. (2007). Adaptive Non-Interventional Heuristics for Covariation Detection in Causal Induction: Model Comparison and Rational Analysis. Cognitive Science: A Multidisciplinary Journal, 31(5), 765–814. \url{https://doi.org/10.1080/03640210701530755}.

‌

\bibitem{hattori03}
Hattori, M. (2003). Adaptive heuristics of covariation detection: A model of causal induction. \url{https://www.researchgate.net/publication/245197199_Adaptive_heuristics_of_covariation_detection_A_model_of_causal_induction}.

\bibitem{hattori01}
Hattori, M. (2001) Ingakinou-no niyouin heuristic model [A dual-factor heuristic model of causal induction],
Cognitive Studies: Bulletin of the Japanese Cognitive Science Society, 8, 444-453. \url{https://www.researchgate.net/publication/316814852_A_Dual-Factor_Heuristics_Model_of_Causal_Induction}.

\bibitem{ander95}
Anderson, J. R., \& Sheu, C. F. (1995). Causal inferences as perceptual judgements. Memory \& cognition, 23(4), 510–524. \url{https://doi.org/10.3758/bf03197251}.

\bibitem{oaksford}
Oaksford, M., \& Chater, N. (1994). A rational analysis of the selection task as optimal data selection. Psychological Review, 101(4), 608–631. \url{https://doi.org/10.1037/0033-295x.101.4.608}.

\bibitem{kaden}
Kaden, M., Hermann, W., \& Villmann, T. (2014). Optimization of General Statistical Accuracy Measures for Classification Based on Learning Vector Quantization. The European Symposium on Artificial Neural Networks. \url{http://www.i6doc.com/fr/livre/?GCOI=28001100432440}.


\end{thebibliography}

\end{document}